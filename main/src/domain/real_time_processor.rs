use crate::domain::{
    classify_midi_message, CompoundMappingSource, ControlMainTask, ControlMode, ControlOptions,
    LifecycleMidiMessage, LifecyclePhase, MappingCompartment, MappingId, MidiClockCalculator,
    MidiMessageClassification, MidiSourceScanner, NormalMainTask, PartialControlMatch,
    RealTimeMapping, VirtualSourceValue,
};
use helgoboss_learn::{ControlValue, MidiSource, MidiSourceValue, RawMidiEvent};
use helgoboss_midi::{
    Channel, ControlChange14BitMessage, ControlChange14BitMessageScanner, DataEntryByteOrder,
    ParameterNumberMessage, PollingParameterNumberMessageScanner, RawShortMessage, ShortMessage,
};
use reaper_high::{MidiInputDevice, MidiOutputDevice, Reaper};
use reaper_medium::{Hz, MidiFrameOffset, SendMidiTime};
use slog::debug;
use std::collections::HashMap;

use crate::core::Global;
use enum_map::{enum_map, EnumMap};
use std::ptr::null_mut;
use std::time::Duration;
use vst::api::{EventType, Events, MidiEvent, SysExEvent};
use vst::host::Host;
use vst::plugin::HostCallback;

const NORMAL_BULK_SIZE: usize = 100;
const FEEDBACK_BULK_SIZE: usize = 100;

#[derive(Debug)]
pub struct RealTimeProcessor {
    instance_id: String,
    logger: slog::Logger,
    // Synced processing settings
    control_mode: ControlMode,
    midi_control_input: MidiControlInput,
    midi_feedback_output: Option<MidiFeedbackOutput>,
    mappings: EnumMap<MappingCompartment, HashMap<MappingId, RealTimeMapping>>,
    let_matched_events_through: bool,
    let_unmatched_events_through: bool,
    // State
    control_is_globally_enabled: bool,
    feedback_is_globally_enabled: bool,
    // Inter-thread communication
    normal_task_receiver: crossbeam_channel::Receiver<NormalRealTimeTask>,
    feedback_task_receiver: crossbeam_channel::Receiver<FeedbackRealTimeTask>,
    feedback_task_sender: crossbeam_channel::Sender<FeedbackRealTimeTask>,
    normal_main_task_sender: crossbeam_channel::Sender<NormalMainTask>,
    control_main_task_sender: crossbeam_channel::Sender<ControlMainTask>,
    // Scanners for more complex MIDI message types
    nrpn_scanner: PollingParameterNumberMessageScanner,
    cc_14_bit_scanner: ControlChange14BitMessageScanner,
    // For source learning
    midi_source_scanner: MidiSourceScanner,
    // For MIDI timing clock calculations
    midi_clock_calculator: MidiClockCalculator,
}

impl RealTimeProcessor {
    pub fn new(
        instance_id: String,
        parent_logger: &slog::Logger,
        normal_task_receiver: crossbeam_channel::Receiver<NormalRealTimeTask>,
        feedback_task_receiver: crossbeam_channel::Receiver<FeedbackRealTimeTask>,
        feedback_task_sender: crossbeam_channel::Sender<FeedbackRealTimeTask>,
        normal_main_task_sender: crossbeam_channel::Sender<NormalMainTask>,
        control_main_task_sender: crossbeam_channel::Sender<ControlMainTask>,
    ) -> RealTimeProcessor {
        use MappingCompartment::*;
        RealTimeProcessor {
            instance_id,
            logger: parent_logger.new(slog::o!("struct" => "RealTimeProcessor")),
            control_mode: ControlMode::Controlling,
            normal_task_receiver,
            feedback_task_receiver,
            feedback_task_sender,
            normal_main_task_sender,
            control_main_task_sender,
            mappings: enum_map! {
                ControllerMappings => HashMap::with_capacity(1000),
                MainMappings => HashMap::with_capacity(5000),
            },
            let_matched_events_through: false,
            let_unmatched_events_through: false,
            nrpn_scanner: PollingParameterNumberMessageScanner::new(Duration::from_millis(1)),
            cc_14_bit_scanner: Default::default(),
            midi_control_input: MidiControlInput::FxInput,
            midi_feedback_output: None,
            midi_source_scanner: Default::default(),
            midi_clock_calculator: Default::default(),
            control_is_globally_enabled: true,
            feedback_is_globally_enabled: true,
        }
    }

    pub fn process_incoming_midi_from_vst(
        &mut self,
        frame_offset: MidiFrameOffset,
        msg: RawShortMessage,
        is_reaper_generated: bool,
        host: &HostCallback,
    ) {
        if self.midi_control_input == MidiControlInput::FxInput {
            if is_reaper_generated {
                // Ignore note off messages which are a result of starting the transport. They
                // are generated by REAPER in order to stop instruments from sounding. But ReaLearn
                // is not an instrument in the classical sense. We don't want to reset target values
                // just because play has been pressed!
                self.process_unmatched_short(msg, Caller::Vst(host));
                return;
            }
            self.process_incoming_midi(frame_offset, msg, Caller::Vst(host));
        } else {
            // #33 Even though MIDI input device is not set to <FX input>, we want to be able to
            // influence whether messages are let through or not. In this case, FX input events
            // are always unmatched.
            if self.let_unmatched_events_through {
                self.send_short_midi_to_fx_output(msg, Caller::Vst(host))
            }
        }
    }

    pub fn run_from_vst(&mut self, _sample_count: usize, host: &HostCallback) {
        if self.get_feedback_driver() == Driver::Vst {
            self.process_feedback_tasks(Caller::Vst(host));
        }
    }

    /// This should be regularly called by audio hook in normal mode.
    pub fn run_from_audio_hook_all(&mut self, sample_count: usize) {
        self.run_from_audio_hook_essential(sample_count);
        self.run_from_audio_hook_control_and_learn();
    }

    /// This should be regularly called by audio hook even during global MIDI source learning.
    pub fn run_from_audio_hook_essential(&mut self, sample_count: usize) {
        // Increase MIDI clock calculator's sample counter
        self.midi_clock_calculator
            .increase_sample_counter_by(sample_count as u64);
        // Process occasional tasks sent from other thread (probably main thread)
        let normal_task_count = self.normal_task_receiver.len();
        for task in self.normal_task_receiver.try_iter().take(NORMAL_BULK_SIZE) {
            use NormalRealTimeTask::*;
            match task {
                UpdateControlIsGloballyEnabled(is_enabled) => {
                    self.control_is_globally_enabled = is_enabled;
                }
                UpdateFeedbackIsGloballyEnabled(is_enabled) => {
                    // Handle lifecycle MIDI
                    if self.midi_feedback_output.is_some()
                        && is_enabled != self.feedback_is_globally_enabled
                    {
                        self.send_lifecycle_midi_for_all_mappings(is_enabled.into());
                    }
                    // Set
                    self.feedback_is_globally_enabled = is_enabled;
                }
                UpdateAllMappings(compartment, mappings) => {
                    debug!(
                        self.logger,
                        "Updating {} {}...",
                        mappings.len(),
                        compartment
                    );
                    // Handle deactivation MIDI
                    if self.processor_feedback_is_effectively_on() {
                        self.send_lifecycle_midi_for_all_mappings_in(
                            compartment,
                            LifecyclePhase::Deactivation,
                        );
                    }
                    // Set
                    self.mappings[compartment] =
                        mappings.into_iter().map(|m| (m.id(), m)).collect();
                    // Handle activation MIDI
                    if self.processor_feedback_is_effectively_on() {
                        self.send_lifecycle_midi_for_all_mappings_in(
                            compartment,
                            LifecyclePhase::Activation,
                        );
                    }
                }
                UpdateSingleMapping(compartment, m) => {
                    debug!(
                        self.logger,
                        "Updating single {} {:?}...",
                        compartment,
                        m.id()
                    );
                    // Handle activation MIDI
                    if self.processor_feedback_is_effectively_on() {
                        let was_on_before = self.mappings[compartment]
                            .get(&m.id())
                            .map_or(false, |m| m.feedback_is_effectively_on());
                        let is_on_now = m.feedback_is_effectively_on();
                        if is_on_now {
                            self.send_lifecycle_midi_to_feedback_output_from_audio_hook(
                                compartment,
                                &*m,
                                LifecyclePhase::Activation,
                            );
                        } else if was_on_before {
                            self.send_lifecycle_midi_to_feedback_output_from_audio_hook(
                                compartment,
                                &*m,
                                LifecyclePhase::Deactivation,
                            );
                        }
                    }
                    // Insert
                    self.mappings[compartment].insert(m.id(), *m);
                }
                UpdateTargetActivations(compartment, activation_updates) => {
                    // Also log sample count in order to be sure about invocation order
                    // (timestamp is not accurate enough on e.g. selection changes).
                    // TODO-low We should use an own logger and always log the sample count
                    //  automatically.
                    debug!(
                        self.logger,
                        "Update target activations in {} at {} samples...",
                        compartment,
                        self.midi_clock_calculator.current_sample_count()
                    );
                    // Apply updates
                    for update in activation_updates.iter() {
                        if let Some(m) = self.mappings[compartment].get_mut(&update.id) {
                            m.update_target_activation(update.is_active);
                        }
                    }
                    // Handle lifecycle MIDI
                    if self.processor_feedback_is_effectively_on() {
                        for update in activation_updates.iter() {
                            if let Some(m) = self.mappings[compartment].get(&update.id) {
                                if m.feedback_is_effectively_on_ignoring_target_activation() {
                                    self.send_lifecycle_midi_to_feedback_output_from_audio_hook(
                                        compartment,
                                        m,
                                        update.is_active.into(),
                                    );
                                }
                            }
                        }
                    }
                }
                UpdateSettings {
                    let_matched_events_through,
                    let_unmatched_events_through,
                    midi_control_input,
                    midi_feedback_output,
                } => {
                    debug!(self.logger, "Updating settings...");
                    let feedback_output_changing =
                        midi_feedback_output != self.midi_feedback_output;
                    // Handle deactivation
                    if self.processor_feedback_is_effectively_on() && feedback_output_changing {
                        self.send_lifecycle_midi_for_all_mappings(LifecyclePhase::Deactivation);
                    }
                    // Update settings
                    self.let_matched_events_through = let_matched_events_through;
                    self.let_unmatched_events_through = let_unmatched_events_through;
                    self.midi_control_input = midi_control_input;
                    self.midi_feedback_output = midi_feedback_output;
                    // Handle activation
                    if self.processor_feedback_is_effectively_on() && feedback_output_changing {
                        self.send_lifecycle_midi_for_all_mappings(LifecyclePhase::Activation);
                    }
                }
                UpdateSampleRate(sample_rate) => {
                    debug!(self.logger, "Updating sample rate");
                    self.midi_clock_calculator.update_sample_rate(sample_rate);
                }
                StartLearnSource {
                    allow_virtual_sources,
                } => {
                    debug!(self.logger, "Start learning source");
                    self.control_mode = ControlMode::LearningSource {
                        allow_virtual_sources,
                        osc_arg_index_hint: None,
                    };
                    self.midi_source_scanner.reset();
                }
                DisableControl => {
                    debug!(self.logger, "Disable control");
                    self.control_mode = ControlMode::Disabled;
                }
                ReturnToControlMode => {
                    debug!(self.logger, "Return to control mode");
                    self.control_mode = ControlMode::Controlling;
                    self.nrpn_scanner.reset();
                    self.cc_14_bit_scanner.reset();
                }
                LogDebugInfo => {
                    self.log_debug_info(normal_task_count);
                }
                UpdateMappingActivations(compartment, activation_updates) => {
                    debug!(self.logger, "Update mapping activations...");
                    // Apply updates
                    for update in activation_updates.iter() {
                        if let Some(m) = self.mappings[compartment].get_mut(&update.id) {
                            m.update_activation(update.is_active);
                        }
                    }
                    // Handle lifecycle MIDI
                    if self.processor_feedback_is_effectively_on() {
                        for update in activation_updates.iter() {
                            if let Some(m) = self.mappings[compartment].get(&update.id) {
                                if m.feedback_is_effectively_on_ignoring_mapping_activation() {
                                    self.send_lifecycle_midi_to_feedback_output_from_audio_hook(
                                        compartment,
                                        m,
                                        update.is_active.into(),
                                    );
                                }
                            }
                        }
                    }
                }
            }
        }
        // It's better to send feedback after processing the settings update - otherwise there's the
        // danger that feedback it sent to the wrong device or not at all.
        if self.get_feedback_driver() == Driver::AudioHook {
            self.process_feedback_tasks(Caller::AudioHook);
        }
    }

    fn processor_feedback_is_effectively_on(&self) -> bool {
        self.feedback_is_globally_enabled && self.midi_feedback_output.is_some()
    }

    fn send_lifecycle_midi_for_all_mappings(&self, phase: LifecyclePhase) {
        for compartment in MappingCompartment::enum_iter() {
            self.send_lifecycle_midi_for_all_mappings_in(compartment, phase);
        }
    }

    fn send_lifecycle_midi_for_all_mappings_in(
        &self,
        compartment: MappingCompartment,
        phase: LifecyclePhase,
    ) {
        for m in self.mappings[compartment].values() {
            if m.feedback_is_effectively_on() {
                self.send_lifecycle_midi_to_feedback_output_from_audio_hook(compartment, m, phase);
            }
        }
    }

    /// This should *not* be called by the global audio hook when it's globally learning sources
    /// because we want to pause controlling in that case!
    fn run_from_audio_hook_control_and_learn(&mut self) {
        // Read MIDI events if MIDI control input set to device
        if let MidiControlInput::Device(dev) = self.midi_control_input {
            dev.with_midi_input(|mi| {
                if let Some(mi) = mi {
                    for evt in mi.get_read_buf().enum_items(0) {
                        // Current control mode is checked further down the callstack. No need to
                        // check it here.
                        self.process_incoming_midi(
                            evt.frame_offset(),
                            evt.message().to_other(),
                            Caller::AudioHook,
                        );
                    }
                }
            });
        }
        match self.control_mode {
            ControlMode::Disabled => {}
            ControlMode::Controlling => {
                // This NRPN scanner is just for controlling, not for learning.
                if self.control_is_globally_enabled {
                    // Poll (N)RPN scanner
                    for ch in 0..16 {
                        if let Some(nrpn_msg) = self.nrpn_scanner.poll(Channel::new(ch)) {
                            self.process_incoming_midi_normal_nrpn(nrpn_msg, Caller::AudioHook);
                        }
                    }
                }
            }
            ControlMode::LearningSource {
                allow_virtual_sources,
                ..
            } => {
                // Poll source scanner if we are learning a source currently (local learning)
                if let Some((source, _)) = self.midi_source_scanner.poll() {
                    self.learn_source(source, allow_virtual_sources);
                }
            }
        }
    }

    /// There's an important difference between using audio hook or VST plug-in as driver:
    /// VST processing stops e.g. when project paused and track not armed or on input FX chain and
    /// track not armed. The result is that control, feedback, mapping updates and many other things
    /// wouldn't work anymore. That's why we prefer audio hook whenever possible. However, we can't
    /// use the audio hook if we need access to the VST plug-in host callback because it's dangerous
    /// (would crash when plug-in gone) and somehow strange (although it seems to work).
    ///
    /// **IMPORTANT**: If "MIDI control input" is set to a MIDI device, it's very important that
    /// `run()` is called either just from the VST or just from the audio hook. If both do it,
    /// the MIDI messages are processed **twice**!!! Easy solution: Never have two drivers.
    fn get_feedback_driver(&self) -> Driver {
        use Driver::*;
        match self.midi_feedback_output {
            // Feedback not sent at all. We still want to "eat" any remaining feedback messages.
            // We do everything in the audio hook because it's more reliable.
            None => AudioHook,
            // Feedback sent directly to device. Same here: We let the audio hook do everything in
            // order to not run into surprising situations where control or feedback don't work.
            Some(MidiFeedbackOutput::Device(_)) => AudioHook,
            // Feedback sent to FX output. Here we have to be more careful because sending feedback
            // to FX output involves host callback invocation. This can only be done from the VST
            // plug-in.
            Some(MidiFeedbackOutput::FxOutput) => Vst,
        }
    }

    fn process_feedback_tasks(&self, caller: Caller) {
        // Process (frequent) feedback tasks sent from other thread (probably main thread)
        for task in self
            .feedback_task_receiver
            .try_iter()
            .take(FEEDBACK_BULK_SIZE)
        {
            use FeedbackRealTimeTask::*;
            match task {
                Feedback(v) => {
                    self.send_midi_feedback(&v, caller);
                }
                ClearFeedback => {
                    self.clear_feedback(caller);
                }
                SendLifecycleMidi(compartment, mapping_id, phase) => {
                    if let Some(m) = self.mappings[compartment].get(&mapping_id) {
                        self.send_lifecycle_midi_to_fx_output(
                            m.lifecycle_midi_messages(phase),
                            caller,
                        );
                    }
                }
            }
        }
    }

    fn clear_feedback(&self, caller: Caller) {
        // TODO-medium Maybe also send some "All CCs/notes off message" or even device specific
        //  "All lights off" messages in future ... although this is something which might
        //  not be that good if there are still other ReaLearn instances having feedback control
        //  over this MIDI output.
        for m in self.all_mappings() {
            if let Some(source_value) = m.zero_feedback_midi_source_value() {
                self.send_midi_feedback(&source_value, caller);
            }
        }
    }

    fn log_debug_info(&self, task_count: usize) {
        // Summary
        let msg = format!(
            "\n\
            # Real-time processor\n\
            \n\
            - State: {:?} \n\
            - Total main mapping count: {} \n\
            - Enabled main mapping count: {} \n\
            - Total controller mapping count: {} \n\
            - Enabled controller mapping count: {} \n\
            - Normal task count: {} \n\
            - Feedback task count: {} \n\
            ",
            self.control_mode,
            self.mappings[MappingCompartment::MainMappings].len(),
            self.mappings[MappingCompartment::MainMappings]
                .values()
                .filter(|m| m.control_is_effectively_on())
                .count(),
            self.mappings[MappingCompartment::ControllerMappings].len(),
            self.mappings[MappingCompartment::ControllerMappings]
                .values()
                .filter(|m| m.control_is_effectively_on())
                .count(),
            task_count,
            self.feedback_task_receiver.len(),
        );
        Global::task_support()
            .do_in_main_thread_asap(move || {
                Reaper::get().show_console_msg(msg);
            })
            .unwrap();
        // Detailled
        println!(
            "\n\
            # Real-time processor\n\
            \n\
            {:#?}
            ",
            self
        );
    }

    fn process_incoming_midi(
        &mut self,
        frame_offset: MidiFrameOffset,
        msg: RawShortMessage,
        caller: Caller,
    ) {
        use MidiMessageClassification::*;
        match classify_midi_message(msg) {
            Normal => self.process_incoming_midi_normal(msg, caller),
            Ignored => {
                // ReaLearn doesn't process those. Forward them if user wants it.
                self.process_unmatched_short(msg, caller);
            }
            Timing => {
                // Timing clock messages are treated special (calculates BPM).
                // This is control-only, we never learn it.
                if self.control_is_globally_enabled {
                    if let Some(bpm) = self.midi_clock_calculator.feed(frame_offset) {
                        let source_value = MidiSourceValue::<RawShortMessage>::Tempo(bpm);
                        self.control_midi(&source_value);
                    }
                }
            }
        }
    }

    /// This basically splits the stream of short MIDI messages into 3 streams:
    ///
    /// - (N)RPN messages
    /// - 14-bit CC messages
    /// - Short MIDI messaages
    fn process_incoming_midi_normal(&mut self, msg: RawShortMessage, caller: Caller) {
        match self.control_mode {
            ControlMode::Controlling => {
                if self.control_is_globally_enabled {
                    if let Some(nrpn_msg) = self.nrpn_scanner.feed(&msg) {
                        self.process_incoming_midi_normal_nrpn(nrpn_msg, caller);
                    }
                    if let Some(cc14_msg) = self.cc_14_bit_scanner.feed(&msg) {
                        self.process_incoming_midi_normal_cc14(cc14_msg, caller);
                    }
                    // Even if an composite message ((N)RPN or CC 14-bit) was scanned, we still
                    // process the plain short MIDI message. This is desired.
                    // Rationale: If there's no mapping with a composite source
                    // of this kind, then all the CCs potentially involved in
                    // composite messages can still be used separately (e.g. CC
                    // 6, 38, 98, etc.). That's important! However, if there's
                    // at least one mapping source that listens to composite
                    // messages of the incoming kind, we need to make sure that the
                    // single messages can't be used anymore! Otherwise it would be
                    // confusing. They are consumed. That's the reason why
                    // we do the consumption check at a later state.
                    self.process_incoming_midi_normal_plain(msg, caller);
                }
            }
            ControlMode::LearningSource {
                allow_virtual_sources,
                ..
            } => {
                if let Some(source) = self.midi_source_scanner.feed_short(msg, None) {
                    self.learn_source(source, allow_virtual_sources);
                }
            }
            ControlMode::Disabled => {}
        };
    }

    fn process_incoming_midi_normal_nrpn(&mut self, msg: ParameterNumberMessage, caller: Caller) {
        let source_value = MidiSourceValue::<RawShortMessage>::ParameterNumber(msg);
        let matched = self.control_midi(&source_value);
        if self.midi_control_input != MidiControlInput::FxInput {
            return;
        }
        if (matched && self.let_matched_events_through)
            || (!matched && self.let_unmatched_events_through)
        {
            for m in msg
                .to_short_messages::<RawShortMessage>(DataEntryByteOrder::MsbFirst)
                .iter()
                .flatten()
            {
                self.send_short_midi_to_fx_output(*m, caller);
            }
        }
    }

    fn learn_source(&mut self, source: MidiSource, allow_virtual_sources: bool) {
        // If plug-in dropped, the receiver might be gone already because main processor is
        // unregistered synchronously.
        let _ = self
            .normal_main_task_sender
            .try_send(NormalMainTask::LearnMidiSource {
                source,
                allow_virtual_sources,
            });
    }

    fn process_incoming_midi_normal_cc14(
        &mut self,
        msg: ControlChange14BitMessage,
        caller: Caller,
    ) {
        let source_value = MidiSourceValue::<RawShortMessage>::ControlChange14Bit(msg);
        let matched = self.control_midi(&source_value);
        if self.midi_control_input != MidiControlInput::FxInput {
            return;
        }
        if (matched && self.let_matched_events_through)
            || (!matched && self.let_unmatched_events_through)
        {
            for m in msg.to_short_messages::<RawShortMessage>().iter() {
                self.send_short_midi_to_fx_output(*m, caller);
            }
        }
    }

    fn process_incoming_midi_normal_plain(&mut self, msg: RawShortMessage, caller: Caller) {
        let source_value = MidiSourceValue::Plain(msg);
        if self.is_consumed_by_at_least_one_source(msg) {
            // Some short MIDI messages are just parts of bigger composite MIDI messages,
            // e.g. (N)RPN or 14-bit CCs. If we reach this point, the incoming message
            // could potentially match one of the (N)RPN or 14-bit CC mappings in the list
            // and therefore doesn't qualify anymore as a candidate for normal CC sources.
            return;
        }
        let matched = self.control_midi(&source_value);
        if matched {
            self.process_matched_short(msg, caller);
        } else {
            self.process_unmatched_short(msg, caller);
        }
    }

    fn all_mappings(&self) -> impl Iterator<Item = &RealTimeMapping> {
        MappingCompartment::enum_iter()
            .map(move |compartment| self.mappings[compartment].values())
            .flatten()
    }

    /// Returns whether this source value matched one of the mappings.
    fn control_midi(&mut self, value: &MidiSourceValue<RawShortMessage>) -> bool {
        // We do pattern matching in order to use Rust's borrow splitting.
        let matched_controller = if let [ref mut controller_mappings, ref main_mappings] =
            self.mappings.as_mut_slice()
        {
            control_controller_mappings_midi(
                &self.control_main_task_sender,
                controller_mappings,
                main_mappings,
                value,
            )
        } else {
            unreachable!()
        };
        let matched_main = self.control_main_mappings_midi(value);
        matched_main || matched_controller
    }

    fn control_main_mappings_midi(
        &mut self,
        source_value: &MidiSourceValue<RawShortMessage>,
    ) -> bool {
        let compartment = MappingCompartment::MainMappings;
        let mut matched = false;
        for m in self.mappings[compartment]
            .values_mut()
            // The UI prevents creating main mappings with virtual targets but a JSON import
            // doesn't. Check again that it's a REAPER target.
            .filter(|m| m.control_is_effectively_on() && m.has_reaper_target())
        {
            if let CompoundMappingSource::Midi(s) = &m.source() {
                if let Some(control_value) = s.control(source_value) {
                    forward_control_to_main_processor(
                        &self.control_main_task_sender,
                        compartment,
                        m.id(),
                        control_value,
                        ControlOptions {
                            enforce_send_feedback_after_control: false,
                        },
                    );
                    matched = true;
                }
            }
        }
        matched
    }

    fn process_matched_short(&self, msg: RawShortMessage, caller: Caller) {
        if self.midi_control_input != MidiControlInput::FxInput {
            return;
        }
        if !self.let_matched_events_through {
            return;
        }
        self.send_short_midi_to_fx_output(msg, caller);
    }

    fn process_unmatched_short(&self, msg: RawShortMessage, caller: Caller) {
        if self.midi_control_input != MidiControlInput::FxInput {
            return;
        }
        if !self.let_unmatched_events_through {
            return;
        }
        self.send_short_midi_to_fx_output(msg, caller);
    }

    fn is_consumed_by_at_least_one_source(&self, msg: RawShortMessage) -> bool {
        self.all_mappings()
            .any(|m| m.control_is_effectively_on() && m.consumes(msg))
    }

    fn send_midi_feedback(&self, value: &MidiSourceValue<RawShortMessage>, caller: Caller) {
        if let Some(output) = self.midi_feedback_output {
            if let MidiSourceValue::Raw(msg) = value {
                match output {
                    MidiFeedbackOutput::FxOutput => {
                        self.send_raw_midi_to_fx_output(msg, caller);
                    }
                    MidiFeedbackOutput::Device(dev) => {
                        dev.with_midi_output(|mo| {
                            if let Some(mo) = mo {
                                mo.send_msg(&**msg, SendMidiTime::Instantly);
                            }
                        });
                    }
                };
            } else {
                let shorts = value.to_short_messages(DataEntryByteOrder::MsbFirst);
                if shorts[0].is_none() {
                    return;
                }
                match output {
                    MidiFeedbackOutput::FxOutput => {
                        for short in shorts.iter().flatten() {
                            self.send_short_midi_to_fx_output(*short, caller);
                        }
                    }
                    MidiFeedbackOutput::Device(dev) => {
                        dev.with_midi_output(|mo| {
                            if let Some(mo) = mo {
                                for short in shorts.iter().flatten() {
                                    mo.send(*short, SendMidiTime::Instantly);
                                }
                            }
                        });
                    }
                };
            }
        }
    }

    fn send_lifecycle_midi_to_feedback_output_from_audio_hook(
        &self,
        compartment: MappingCompartment,
        m: &RealTimeMapping,
        phase: LifecyclePhase,
    ) {
        if let Some(output) = self.midi_feedback_output {
            match output {
                MidiFeedbackOutput::FxOutput => {
                    // We can't send it now because we don't have safe access to the host callback
                    // because this method is being called from the audio hook.
                    let _ = self.feedback_task_sender.try_send(
                        FeedbackRealTimeTask::SendLifecycleMidi(compartment, m.id(), phase),
                    );
                }
                MidiFeedbackOutput::Device(dev) => {
                    dev.with_midi_output(|mo| {
                        if let Some(mo) = mo {
                            for m in m.lifecycle_midi_messages(phase) {
                                match m {
                                    LifecycleMidiMessage::Short(msg) => {
                                        mo.send(*msg, SendMidiTime::Instantly);
                                    }
                                    LifecycleMidiMessage::Raw(data) => {
                                        mo.send_msg(&**data, SendMidiTime::Instantly);
                                    }
                                }
                            }
                        }
                    });
                }
            };
        }
    }

    fn send_lifecycle_midi_to_fx_output(&self, messages: &[LifecycleMidiMessage], caller: Caller) {
        for m in messages {
            match m {
                LifecycleMidiMessage::Short(msg) => self.send_short_midi_to_fx_output(*msg, caller),
                LifecycleMidiMessage::Raw(data) => self.send_raw_midi_to_fx_output(data, caller),
            }
        }
    }

    fn send_raw_midi_to_fx_output(&self, data: &RawMidiEvent, caller: Caller) {
        let host = match caller {
            Caller::Vst(h) => h,
            _ => return,
        };
        let event = build_sysex_midi_vst_event(data.bytes());
        let events = build_vst_events(&event as *const _ as _);
        host.process_events(&events);
    }

    fn send_short_midi_to_fx_output(&self, msg: RawShortMessage, caller: Caller) {
        let host = match caller {
            Caller::Vst(h) => h,
            _ => {
                // We must not forward MIDI to VST output if this was called from the global audio
                // hook. First, it could lead to strange effects because
                // `HostCallback::process_events()` is supposed to be called only
                // from the VST processing method. Second, it could even lead to a
                // crash because the real-time processor is removed from
                // the audio hook *after* the plug-in has been already unregistered, and then
                // invoking the host callback (in particular dereferencing the
                // AEffect) would be illegal. This is just a last safety check.
                // Processing should stop before even calling this method.
                return;
            }
        };
        let event = build_short_midi_vst_event(msg);
        let events = build_vst_events(&event as *const _ as _);
        host.process_events(&events);
    }
}

fn build_vst_events(event: *mut vst::api::Event) -> Events {
    Events {
        num_events: 1,
        _reserved: 0,
        events: [event, null_mut()],
    }
}

fn build_sysex_midi_vst_event(bytes: &[u8]) -> SysExEvent {
    SysExEvent {
        event_type: EventType::SysEx,
        byte_size: std::mem::size_of::<SysExEvent>() as _,
        delta_frames: 0,
        _flags: 0,
        data_size: bytes.len() as _,
        _reserved1: 0,
        system_data: bytes as *const _ as _,
        _reserved2: 0,
    }
}

fn build_short_midi_vst_event(msg: RawShortMessage) -> MidiEvent {
    let bytes = msg.to_bytes();
    MidiEvent {
        event_type: EventType::Midi,
        byte_size: std::mem::size_of::<MidiEvent>() as _,
        delta_frames: 0,
        flags: vst::api::MidiEventFlags::REALTIME_EVENT.bits(),
        note_length: 0,
        note_offset: 0,
        midi_data: [bytes.0, bytes.1.get(), bytes.2.get()],
        _midi_reserved: 0,
        detune: 0,
        note_off_velocity: 0,
        _reserved1: 0,
        _reserved2: 0,
    }
}

#[derive(Copy, Clone)]
enum Caller<'a> {
    Vst(&'a HostCallback),
    AudioHook,
}

#[derive(Debug)]
pub struct RealTimeSender<T> {
    sender: crossbeam_channel::Sender<T>,
}

impl<T> Clone for RealTimeSender<T> {
    fn clone(&self) -> Self {
        Self {
            sender: self.sender.clone(),
        }
    }
}

impl<T> RealTimeSender<T> {
    pub fn new(sender: crossbeam_channel::Sender<T>) -> Self {
        Self { sender }
    }

    pub fn send(&self, task: T) -> Result<(), &'static str> {
        self.sender
            .try_send(task)
            .map_err(|_| "real-time channel full or disconnected")
        // if Reaper::get().audio_is_running() || self.sender.ca{
        //     self.sender
        //         .try_send(task)
        //         .map_err(|_| "real-time channel full or disconnected")
        // } else {
        //     return Err("audio not running");
        // }
    }
}

/// A task which is sent from time to time.
#[derive(Debug)]
pub enum NormalRealTimeTask {
    UpdateAllMappings(MappingCompartment, Vec<RealTimeMapping>),
    UpdateSingleMapping(MappingCompartment, Box<RealTimeMapping>),
    UpdateSettings {
        let_matched_events_through: bool,
        let_unmatched_events_through: bool,
        midi_control_input: MidiControlInput,
        midi_feedback_output: Option<MidiFeedbackOutput>,
    },
    /// This takes care of propagating target activation states (for non-virtual mappings).
    UpdateTargetActivations(MappingCompartment, Vec<ActivationChange>),
    /// Updates the activation state of multiple mappings (for non-virtual mappings).
    ///
    /// The given vector contains updates just for affected mappings. This is because when a
    /// parameter update occurs we can determine in a very granular way which targets are affected.
    UpdateMappingActivations(MappingCompartment, Vec<ActivationChange>),
    LogDebugInfo,
    UpdateSampleRate(Hz),
    StartLearnSource {
        allow_virtual_sources: bool,
    },
    DisableControl,
    ReturnToControlMode,
    UpdateControlIsGloballyEnabled(bool),
    UpdateFeedbackIsGloballyEnabled(bool),
}

#[derive(Copy, Clone, Debug)]
pub struct MappingActivationEffect {
    pub id: MappingId,
    pub active_1_effect: Option<bool>,
    pub active_2_effect: Option<bool>,
}

impl MappingActivationEffect {
    pub fn new(
        id: MappingId,
        active_1_effect: Option<bool>,
        active_2_effect: Option<bool>,
    ) -> Option<MappingActivationEffect> {
        if active_1_effect.is_none() && active_2_effect.is_none() {
            return None;
        }
        let and = MappingActivationEffect {
            id,
            active_1_effect,
            active_2_effect,
        };
        Some(and)
    }
}

/// Depending on the context this can be about mapping activation or target activation.
///
/// It's important that this reflects an actual change, otherwise the real-time processor might
/// send lifecycle MIDI data in the wrong situations.
#[derive(Copy, Clone, Debug)]
pub struct ActivationChange {
    pub id: MappingId,
    pub is_active: bool,
}

/// A feedback task (which is potentially sent very frequently).
#[derive(Debug)]
pub enum FeedbackRealTimeTask {
    // TODO-low Is it better for performance to push a vector (smallvec) here?
    Feedback(MidiSourceValue<RawShortMessage>),
    /// If this is sent when the main processor is dropped it should be still processed by the
    /// real-time processor before it's gone. Because the real-time processor will be removed
    /// asynchronously after the main processor has been removed synchronously and before actual
    /// removal its `run*` function will still be called. See `RealearnAudioHook` comments for
    /// details.
    ClearFeedback,
    // Used only if feedback output is <FX output>, otherwise done synchronously.
    SendLifecycleMidi(MappingCompartment, MappingId, LifecyclePhase),
}

impl Drop for RealTimeProcessor {
    fn drop(&mut self) {
        debug!(self.logger, "Dropping real-time processor...");
    }
}

/// MIDI source which provides ReaLearn control data.
#[derive(Copy, Clone, Eq, PartialEq, Debug)]
pub enum MidiControlInput {
    /// Processes MIDI messages which are fed into ReaLearn FX.
    FxInput,
    /// Processes MIDI messages coming directly from a MIDI input device.
    Device(MidiInputDevice),
}

/// MIDI destination to which ReaLearn's feedback data is sent.
#[derive(Copy, Clone, Eq, PartialEq, Debug)]
pub enum MidiFeedbackOutput {
    /// Routes feedback messages to the ReaLearn FX output.
    FxOutput,
    /// Routes feedback messages directly to a MIDI output device.
    Device(MidiOutputDevice),
}

fn control_controller_mappings_midi(
    sender: &crossbeam_channel::Sender<ControlMainTask>,
    // Mappings with virtual targets
    controller_mappings: &mut HashMap<MappingId, RealTimeMapping>,
    // Mappings with virtual sources
    main_mappings: &HashMap<MappingId, RealTimeMapping>,
    value: &MidiSourceValue<RawShortMessage>,
) -> bool {
    let mut matched = false;
    for m in controller_mappings
        .values_mut()
        .filter(|m| m.control_is_effectively_on())
    {
        if let Some(control_match) = m.control_midi_virtualizing(value) {
            use PartialControlMatch::*;
            let mapping_matched = match control_match {
                ProcessVirtual(virtual_source_value) => control_main_mappings_virtual(
                    sender,
                    main_mappings,
                    virtual_source_value,
                    ControlOptions {
                        // We inherit "Send feedback after control" to the main processor if it's
                        // enabled for the virtual mapping. That's the easy way to do it.
                        // Downside: If multiple real control elements are mapped to one virtual
                        // control element, "feedback after control" will be sent to all of those,
                        // which is technically not necessary. It would be enough to just send it
                        // to the one that was touched. However, it also doesn't really hurt.
                        enforce_send_feedback_after_control: m
                            .options()
                            .send_feedback_after_control,
                    },
                ),
                ProcessDirect(control_value) => {
                    forward_control_to_main_processor(
                        sender,
                        MappingCompartment::ControllerMappings,
                        m.id(),
                        control_value,
                        ControlOptions {
                            enforce_send_feedback_after_control: false,
                        },
                    );
                    true
                }
            };
            if mapping_matched {
                matched = true;
            }
        }
    }
    matched
}

fn forward_control_to_main_processor(
    sender: &crossbeam_channel::Sender<ControlMainTask>,
    compartment: MappingCompartment,
    mapping_id: MappingId,
    value: ControlValue,
    options: ControlOptions,
) {
    let task = ControlMainTask::Control {
        compartment,
        mapping_id,
        value,
        options,
    };
    // If plug-in dropped, the receiver might be gone already because main processor is
    // unregistered synchronously.
    let _ = sender.try_send(task);
}

/// Returns whether this source value matched one of the mappings.
fn control_main_mappings_virtual(
    sender: &crossbeam_channel::Sender<ControlMainTask>,
    main_mappings: &HashMap<MappingId, RealTimeMapping>,
    value: VirtualSourceValue,
    options: ControlOptions,
) -> bool {
    // Controller mappings can't have virtual sources, so for now we only need to check
    // main mappings.
    let mut matched = false;
    for m in main_mappings
        .values()
        .filter(|m| m.control_is_effectively_on())
    {
        if let CompoundMappingSource::Virtual(s) = &m.source() {
            if let Some(control_value) = s.control(&value) {
                forward_control_to_main_processor(
                    sender,
                    MappingCompartment::MainMappings,
                    m.id(),
                    control_value,
                    options,
                );
                matched = true;
            }
        }
    }
    matched
}

#[derive(Eq, PartialEq)]
enum Driver {
    AudioHook,
    Vst,
}
